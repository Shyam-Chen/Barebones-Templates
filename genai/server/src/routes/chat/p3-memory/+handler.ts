import { randomUUID } from 'node:crypto';
import type { FastifyPluginAsyncTypebox } from '@fastify/type-provider-typebox';
import type { ModelMessage } from 'ai';
import { streamText } from 'ai';

import gemini from '~/utils/gemini.ts';

interface ChatRequestBody {
  conversationId?: ReturnType<typeof randomUUID>; // å°è©±ç·¨è™Ÿï¼Œç¬¬ä¸€æ¬¡è«‹æ±‚æ™‚å¯èƒ½ä¸å­˜åœ¨
  messages: ModelMessage[]; // é€™æ¬¡è«‹æ±‚ä¸­ï¼Œä½¿ç”¨è€…ç™¼é€çš„æ–°è¨Šæ¯ï¼ˆä¾‹å¦‚ï¼Œä¸€å€‹ {role: 'user', content: '...'} çš„é™£åˆ—ï¼‰
}

// æ¨¡æ“¬è³‡æ–™åº«å„²å­˜
// åœ¨æ’ä»¶ä½œç”¨åŸŸå¤–æˆ–æ’ä»¶å…§éƒ¨ä½†å‡½æ•¸å¤–éƒ¨è²æ˜ï¼Œç¢ºä¿å®ƒåœ¨æ‰€æœ‰è«‹æ±‚ä¹‹é–“å…±äº«
// Map çš„éµæ˜¯ conversationId (string)ï¼Œå€¼æ˜¯è©²å°è©±çš„æ‰€æœ‰ ModelMessage é™£åˆ—
const conversationHistory = new Map<
  ChatRequestBody['conversationId'],
  ChatRequestBody['messages']
>();

// ğŸŸ¡
export default (async (app) => {
  // 1. å»ºç«‹å°è©±ç·¨è™Ÿ
  // 2. å°‡å°è©±ç´€éŒ„å„²å­˜è‡³å°è©±ç·¨è™Ÿ
  // 3. ä½¿ç”¨è€…åšç¬¬äºŒæ¬¡ä»¥ä¸Šå›è¦†ï¼Œå°‡å…ˆå‰å°è©±ç´€éŒ„ä¸€ä½µçµ¦ AI æ¨¡å‹ï¼Œä»¥å¯¦ä½œã€ŒçŸ­æœŸè¨˜æ†¶ã€
  app.post('', { sse: true }, async (request, reply) => {
    const body = JSON.parse(request.body as string) as ChatRequestBody;

    let currentConversationId = body.conversationId;

    // å»ºç«‹å°è©±ç·¨è™Ÿ (æˆ–ä½¿ç”¨ç¾æœ‰çš„)
    if (!currentConversationId) {
      currentConversationId = randomUUID();
      // å¦‚æœæ˜¯æ–°çš„å°è©±ï¼Œé€é SSE ç™¼é€ conversationId çµ¦å®¢æˆ¶ç«¯
      // å®¢æˆ¶ç«¯éœ€è¦ç›£è½ 'conversationId' äº‹ä»¶ä¾†ç²å–é€™å€‹ ID
      await reply.sse.send({ event: 'conversationId', data: currentConversationId });
    }

    // å¾ Map ä¸­ç²å–è©²å°è©±çš„æ­·å²ç´€éŒ„
    const previousMessages: ModelMessage[] = conversationHistory.get(currentConversationId) || [];

    // ä½¿ç”¨è€…åšç¬¬äºŒæ¬¡ä»¥ä¸Šå›è¦†ï¼Œå°‡å…ˆå‰å°è©±ç´€éŒ„ä¸€ä½µçµ¦ AI æ¨¡å‹ï¼Œä»¥å¯¦ä½œã€ŒçŸ­æœŸè¨˜æ†¶ã€
    // å°‡å…ˆå‰çš„å°è©±ç´€éŒ„èˆ‡ä½¿ç”¨è€…é€™æ¬¡çš„æ–°è¨Šæ¯åˆä½µï¼Œä½œç‚ºçµ¦ AI æ¨¡å‹çš„å®Œæ•´ä¸Šä¸‹æ–‡
    const messagesForAI: ModelMessage[] = [...previousMessages, ...body.messages];

    let aiResponseContent = ''; // ç”¨æ–¼æ”¶é›† AI çš„å®Œæ•´å›è¦†

    const { textStream } = streamText({
      model: gemini.model,
      system: ``,
      messages: messagesForAI,
    });

    for await (const textPart of textStream) {
      aiResponseContent += textPart; // æ”¶é›† AI çš„å›è¦†ç‰‡æ®µ
      await reply.sse.send({ data: textPart });
    }

    // å°‡å°è©±ç´€éŒ„å„²å­˜è‡³å°è©±ç·¨è™Ÿ
    // å°‡ AI çš„å®Œæ•´å›è¦†ä¹Ÿæ·»åŠ åˆ°å°è©±ç´€éŒ„ä¸­
    const aiMessage: ModelMessage = { role: 'assistant', content: aiResponseContent };
    const updatedHistory: ModelMessage[] = [...messagesForAI, aiMessage];

    // å°‡æ›´æ–°å¾Œçš„å®Œæ•´å°è©±ç´€éŒ„å„²å­˜åˆ° Map ä¸­
    conversationHistory.set(currentConversationId, updatedHistory);

    // çµæŸ SSE é€£æ¥
    return reply.sse.close();
  });

  // [enhancement] Summarize messages
  // [
  //   { role: 'assistant', content: '__SUMMARY_CONTENT__' },
  //   { role: 'user', content: '__USER_CONTENT__' },
  //   { role: 'assistant', content: '__ASSISTANT_CONTENT__' },
  // ]
  // 1. ç•¶è¨Šæ¯éå¤šæ™‚ï¼Œå®šæœŸå°‡èˆŠçš„å°è©±ç´€éŒ„é€²è¡Œæ‘˜è¦ï¼Œä»¥ç¯€çœ Token
  app.post('/summarize', { sse: true }, async (request, reply) => {
    const body = JSON.parse(request.body as string) as { messages: ModelMessage[] };

    const { textStream } = streamText({
      model: gemini.model,
      system: ``,
      messages: body.messages,
    });

    for await (const textPart of textStream) {
      await reply.sse.send({ data: textPart });
    }
  });

  // [in production] Use a checkpointer backed by a database
  app.post('/checkpointer', { sse: true }, async (request, reply) => {
    const body = JSON.parse(request.body as string) as { messages: ModelMessage[] };

    const { textStream } = streamText({
      model: gemini.model,
      system: ``,
      messages: body.messages,
    });

    for await (const textPart of textStream) {
      await reply.sse.send({ data: textPart });
    }
  });
}) as FastifyPluginAsyncTypebox;
